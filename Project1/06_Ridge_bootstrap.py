'''This program performs Ridge regression on a synthetic dataset generated by the Franke Function
and performs bootstrap resampling technique
The program returns plot of Bias Variance trade off against polynomial degree (up to 10) for a given hyper parameter Lamda
Author: R Corseri & L Barreiro'''
#%%

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.utils import resample
from Functions import RidgeReg, DesignMatrix, FrankeFunction
import seaborn as sb

#%%
#Define maximal model complexity
maxdegree= 5

#For Ridge regression, set up the hyper-parameters to investigate
nlambdas = 9
lambdas = np.logspace(-4, 4, nlambdas)

#Number of bootstraps
n_bootstraps = 75

# Generate dataset with n observations
n = 100
x = np.random.uniform(0,1,n)
y = np.random.uniform(0,1,n)

#Define noise
var = 0.01
noise = np.random.normal(0,var,n)

z = FrankeFunction(x,y) + noise 

x = np.array(x).reshape(n,1)
y = np.array(y).reshape(n,1)
x1 = np.hstack((x,y)).reshape(n,2)

#Split train (80%) and test(20%) data before looping on polynomial degree
x_train, x_test, z_train, z_test = train_test_split(x1, z, test_size=0.2)

    
#Scaling not needed

#%%
#Initialize before looping:
TestError = np.zeros(maxdegree)
TrainError = np.zeros(maxdegree)
TestR2 = np.zeros(maxdegree)
TrainR2 = np.zeros(maxdegree)
polydegree = np.zeros(maxdegree)
predictor =[]

error = np.zeros(maxdegree)
bias = np.zeros(maxdegree)
variance = np.zeros(maxdegree)

E = np.zeros((maxdegree,9))

#Initialize bootstrap matrice
z_pred = np.empty((z_test.shape[0],n_bootstraps))

# Loop for subplotting Error-Bias-variance
fig = plt.figure(figsize=(15,12))
c=1

for l in range(nlambdas):
    for degree in range(maxdegree):   
        for i in range(n_bootstraps):
            x_, z_ = resample(x_train,z_train)
      
            X_train = DesignMatrix(x_[:,0],x_[:,1],degree+1)
            X_test = DesignMatrix(x_test[:,0],x_test[:,1],degree+1)
            z_fit, z_pred[:,i], Beta = RidgeReg(X_train, X_test, z_, z_test,lambdas[l])
                    
        z_test = np.reshape(z_test, (len(z_test),1))
        predictor=np.append(predictor,Beta)
        polydegree[degree] = degree+1
           
        error[degree] = np.mean( np.mean((z_test - z_pred)**2, axis=1, keepdims=True) )
        bias[degree] = np.mean( (z_test - np.mean(z_pred, axis=1, keepdims=True))**2 )
        variance[degree] = np.mean( np.var(z_pred, axis=1, keepdims=True) )
        
    E[:,l] = error
    

    plt.subplot(3,3,c)
    plt.plot(range(1,maxdegree+1), error, label = 'Error')
    plt.plot(range(1,maxdegree+1), bias, label = 'Bias')
    plt.plot(range(1,maxdegree+1), variance, label = 'Variance')
    plt.title('lambda = %.0e' %lambdas[l])
    c = c+1

fig.text(0.5, 0.08, 'Model complexity', ha='center')
fig.text(0.07, 0.5, 'Error', va='center', rotation='vertical')
fig.suptitle("Variance-Bias tradeoff for different lambda (Ridge)", fontsize=18, y=0.95)
plt.legend()
plt.savefig("plots/Ridge_Lasso/Ridge_Bias_Variance_trade_off_LAMBDAS.png",dpi=150)
plt.show()

#%%
#Create a heatmap with the error per nlambdas and polynomial degree

heatmap = sb.heatmap(E,annot=True, annot_kws={"size":7}, cmap="coolwarm", xticklabels=lambdas, yticklabels=range(1,maxdegree+1), cbar_kws={'label': 'Mean squared error'})
heatmap.invert_yaxis()
heatmap.set_ylabel("Complexity")
heatmap.set_xlabel("lambda")
heatmap.set_title("MSE heatmap, n_bootstraps =  {:}".format(n_bootstraps))
plt.tight_layout()
plt.savefig("plots/Ridge_Lasso/Ridge_bootstrap_heatmap.png",dpi=150)
plt.show()



